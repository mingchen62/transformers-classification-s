{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'num_train_epochs': 6, 'save_steps':400, 'train_batch_size':32, 'eval_batch_size':8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git_config = {'repo': 'https://github.com/awslabs/amazon-sagemaker-examples.git', 'branch': 'training-scripts'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p3.8xlarge',\n",
    "                    source_dir='email-compliance-bert',\n",
    "                    #git_config=git_config,\n",
    "                    hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-17 01:28:30 Starting - Starting the training job...\n",
      "2019-09-17 01:28:32 Starting - Launching requested ML instances......\n",
      "2019-09-17 01:29:32 Starting - Preparing the instances for training......\n",
      "2019-09-17 01:30:43 Downloading - Downloading input data...\n",
      "2019-09-17 01:31:30 Training - Training image download completed. Training in progress..\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:31,775 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:31,818 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:32,452 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:32,787 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:32,787 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:32,788 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:32,788 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting sklearn (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting uuid (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/63/f42f5aa951ebf2c8dac81f77a8edcc1c218640a2a35a03b9ff2d4aa64c3d/uuid-1.30.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting pytorch-transformers (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\u001b[0m\n",
      "\u001b[31mCollecting scikit-learn (from sklearn->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\u001b[0m\n",
      "\u001b[31mCollecting sentencepiece (from pytorch-transformers->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (2.22.0)\u001b[0m\n",
      "\u001b[31mCollecting sacremoses (from pytorch-transformers->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/df/24/0b86f494d3a5c7531f6d0c77d39fd8f9d42e651244505d3d737e31db9a4d/sacremoses-0.0.33.tar.gz (802kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (1.16.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (1.1.0)\u001b[0m\n",
      "\u001b[31mCollecting regex (from pytorch-transformers->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (4.33.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (1.9.209)\u001b[0m\n",
      "\u001b[31mCollecting joblib>=0.11 (from scikit-learn->sklearn->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (3.0.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (2019.6.16)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (1.25.3)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (2.8)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->-r requirements.txt (line 3)) (1.12.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->-r requirements.txt (line 3)) (0.2.1)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: botocore<1.13.0,>=1.12.209 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->-r requirements.txt (line 3)) (1.12.209)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->-r requirements.txt (line 3)) (0.9.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.209->boto3->pytorch-transformers->-r requirements.txt (line 3)) (2.8.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.209->boto3->pytorch-transformers->-r requirements.txt (line 3)) (0.15.2)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: sklearn, uuid, train, sacremoses, regex\n",
      "  Running setup.py bdist_wheel for sklearn: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for sklearn: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Running setup.py bdist_wheel for uuid: started\n",
      "  Running setup.py bdist_wheel for uuid: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/80/9b/015026567c29fdffe31d91edbe7ba1b17728db79194fca1f21\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p6flytnd/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for sacremoses: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for sacremoses: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/87/56/e40575cca30d12fee8875d523b8878b7aba866a9f03b2fd983\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\u001b[0m\n",
      "\u001b[31mSuccessfully built sklearn uuid train sacremoses regex\u001b[0m\n",
      "\u001b[31mInstalling collected packages: joblib, scikit-learn, sklearn, uuid, sentencepiece, sacremoses, regex, pytorch-transformers, train\u001b[0m\n",
      "\u001b[31mSuccessfully installed joblib-0.13.2 pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.33 scikit-learn-0.21.3 sentencepiece-0.1.83 sklearn-0.0 train-1.0.0 uuid-1.30\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.3 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-09-17 01:31:48,739 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_batch_size\": 32,\n",
      "        \"num_train_epochs\": 6,\n",
      "        \"save_steps\": 400,\n",
      "        \"eval_batch_size\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-09-17-01-28-30-327\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-665028136136/sagemaker-pytorch-2019-09-17-01-28-30-327/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"eval_batch_size\":8,\"num_train_epochs\":6,\"save_steps\":400,\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-1-665028136136/sagemaker-pytorch-2019-09-17-01-28-30-327/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eval_batch_size\":8,\"num_train_epochs\":6,\"save_steps\":400,\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-09-17-01-28-30-327\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-665028136136/sagemaker-pytorch-2019-09-17-01-28-30-327/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--eval_batch_size\",\"8\",\"--num_train_epochs\",\"6\",\"--save_steps\",\"400\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[31mSM_HP_NUM_TRAIN_EPOCHS=6\u001b[0m\n",
      "\u001b[31mSM_HP_SAVE_STEPS=400\u001b[0m\n",
      "\u001b[31mSM_HP_EVAL_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --eval_batch_size 8 --num_train_epochs 6 --save_steps 400 --train_batch_size 32\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mNamespace(adam_epsilon=1e-08, current_host='algo-1', data_dir='/opt/ml/input/data/training', eval_batch_size=8, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hosts=['algo-1'], learning_rate=4e-05, logging_steps=500, max_grad_norm=1.0, max_seq_length=512, model_dir='/opt/ml/model', model_name='bert-base-uncased', model_type='bert', num_gpus=4, num_train_epochs=6, output_dir='./outputs', output_mode='classification', reprocess_input_data=False, save_steps=400, task_name='binary', train_batch_size=32, warmup_steps=0, weight_decay=0, workers=2)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining: use 4 GPUs!\u001b[0m\n",
      "\u001b[31mlen(train_dataloader) 280\u001b[0m\n",
      "\u001b[31margs  {'workers': 2, 'num_train_epochs': 6, 'train_batch_size': 32, 'eval_batch_size': 8, 'weight_decay': 0, 'learning_rate': 4e-05, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'model_type': 'bert', 'model_name': 'bert-base-uncased', 'task_name': 'binary', 'output_mode': 'classification', 'max_seq_length': 512, 'fp16': False, 'fp16_opt_level': 'O1', 'gradient_accumulation_steps': 1, 'logging_steps': 500, 'save_steps': 400, 'reprocess_input_data': False, 'hosts': ['algo-1'], 'current_host': 'algo-1', 'model_dir': '/opt/ml/model', 'data_dir': '/opt/ml/input/data/training', 'output_dir': './outputs', 'num_gpus': 4}\u001b[0m\n",
      "\u001b[31m#0150.649105\u001b[0m\n",
      "\u001b[31malgo-1:103:200 [0] misc/ibvwrap.cu:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31mNCCL version 2.4.2+cuda9.0\u001b[0m\n",
      "\u001b[31m#0150.384912#0150.318247#0150.326684#0150.141499#0150.278126#0150.237001#0150.425965#0150.140065#0150.095901#0150.279403#0150.192553#0150.082923#0150.114403#0150.356602#0150.171319#0150.083161#0150.172877#0150.108639#0150.080735#0150.114943#0150.054529#0150.018188#0150.098547#0150.050725#0150.131985#0150.060862#0150.051143#0150.149693#0150.067721#0150.092976#0150.076747#0150.062487#0150.238076#0150.056779#0150.013747#0150.044676#0150.012091#0150.012284#0150.032334#0150.109436#0150.130928#0150.029198#0150.021308#0150.078333#0150.016581#0150.185714#0150.089728#0150.010034#0150.011647#0150.060124#0150.015929#0150.155414#0150.008882#0150.011225#0150.009415#0150.008000#0150.048580#0150.006157#0150.051563#0150.004870#0150.004092#0150.035005#0150.009173#0150.006927#0150.003784#0150.008793#0150.003282#0150.021542#0150.003524#0150.002577#0150.123867#0150.022139#0150.001653#0150.002699#0150.031821#0150.355536#0150.002800#0150.274884#0150.004799#0150.077833#0150.094206#0150.007578#0150.003004#0150.103172#0150.008746#0150.219256#0150.197190#0150.004095#0150.010408#0150.157236#0150.036057#0150.023750#0150.018441#0150.014570#0150.011138#0150.087279#0150.084303#0150.005802#0150.004818#0150.002430#0150.007672#0150.003856#0150.027142#0150.007486#0150.007081#0150.004685#0150.128559#0150.007721#0150.201834#0150.004813#0150.006708#0150.002214#0150.017907#0150.002597#0150.208896#0150.179194#0150.005129#0150.003333#0150.132453#0150.002658#0150.002926#0150.087318#0150.232807#0150.247487#0150.083364#0150.059858#0150.010241#0150.007861#0150.012648#0150.004434#0150.181744#0150.069378#0150.005967#0150.011435#0150.079177#0150.029170#0150.011470#0150.009943#0150.008298#0150.013622#0150.004969#0150.005433#0150.009094#0150.004146#0150.006448#0150.003196#0150.002822#0150.001405#0150.008929#0150.212292#0150.023174#0150.005308#0150.004935#0150.003268#0150.002082#0150.002596#0150.023680#0150.002772#0150.002863#0150.018934#0150.044542#0150.002696#0150.195733#0150.239274#0150.002586#0150.005810#0150.005460#0150.035646#0150.196669#0150.003713#0150.027491#0150.003865#0150.003980#0150.003587#0150.109323#0150.003767#0150.004414#0150.154005#0150.003761#0150.003811#0150.025732#0150.090532#0150.004870#0150.003879#0150.002104#0150.002272#0150.003283#0150.062714#0150.008585#0150.101095#0150.065879#0150.003523#0150.003932#0150.187466#0150.006726#0150.006138#0150.073695#0150.174784#0150.001591#0150.000997#0150.007010#0150.105122#0150.022285#0150.003129#0150.068848#0150.002057#0150.001070#0150.018578#0150.002865#0150.004665#0150.004355#0150.037729#0150.002607#0150.211842#0150.011655#0150.002554#0150.002474#0150.001807#0150.002089#0150.006602#0150.139890#0150.004337#0150.002561#0150.003327#0150.009248#0150.043001#0150.086001#0150.020480#0150.194489#0150.156694#0150.157996#0150.018505#0150.004987#0150.004101#0150.009592#0150.005309#0150.009369#0150.005138#0150.170779#0150.006971#0150.148218#0150.080561#0150.163846#0150.011034#0150.029487#0150.013036#0150.011215#0150.011087#0150.012272#0150.013297#0150.065898#0150.002753#0150.001941#0150.006433#0150.001166#0150.002892#0150.034425#0150.009335#0150.001015#0150.221402#0150.002860#0150.227319#0150.002049#0150.002838#0150.001696#0150.191141#0150.003161#0150.139236#0150.166301#0150.007788#0150.054915#0150.009273#0150.010192#0150.007971#0150.158806#0150.027302#0150.091647#0150.059833#0150.005926#0150.011261#0150.007890#0150.004990#0150.134621#0150.004441#0150.010860#0150.004353#0150.004140#0150.002645#0150.001845#0150.001826#0150.001907#0150.001957#0150.001647#0150.005175#0150.001111#0150.001161#0150.001629#0150.001213#0150.001854#0150.000942#0150.001185#0150.001022#0150.229654#0150.195674#0150.001014#0150.001155#0150.013014#0150.001607#0150.002543#0150.001930#0150.001512#0150.002451#0150.002009#0150.001889#0150.002472#0150.001948#0150.347844#0150.007943#0150.020847#0150.005936#0150.001803#0150.002438#0150.003455#0150.001508#0150.001878#0150.114345#0150.001750#0150.001602#0150.001499#0150.001621#0150.001089#0150.157224#0150.156352#0150.121574#0150.001603#0150.001355#0150.162865#0150.003341#0150.002930#0150.003007#0150.003311#0150.003489#0150.003526#0150.006644#0150.005569#0150.004492#0150.004926#0150.006065#0150.042138#0150.005429#0150.008981#0150.001920#0150.144070#0150.003210#0150.001992#0150.003664#0150.001706#0150.002818#0150.001591#0150.001465#0150.023926#0150.001322#0150.001020#0150.002447#0150.001401#0150.108060#0150.001153#0150.020717#0150.000822#0150.001389#0150.175242#0150.000856#0150.002230#0150.002746#0150.002391#0150.002711#0150.001301#0150.001596#0150.036727#0150.107667#0150.000412#0150.001455#0150.003518#0150.003199#0150.002167#0150.001453#0150.000420#0150.000768#0150.001103#0150.003329#0150.001936#0150.001790#0150.003243#0150.000870#0150.066321#0150.001758#0150.000473#0150.467018#0150.001172#0150.307215#0150.000732#0150.088766#0150.001498#0150.003876#0150.001717#0150.003460#0150.123086#0150.002551#0150.003626#0150.032414#0150.003299#0150.002957#0150.001858#0150.005910#0150.117546#0150.001453#0150.001876#0150.002429#0150.002383#0150.075293#0150.033949#0150.159475#0150.024617#0150.002176#0150.002979#0150.102829#0150.003713#0150.003177#0150.002827#0150.003400#0150.002890#0150.003581#0150.006105#0150.001818#0150.009477#0150.004724#0150.002545#0150.018564#0150.001287#0150.003707#0150.027777#0150.002415#0150.002691#0150.083126#0150.001393#0150.003427#0150.000494#0150.001849#0150.000552#0150.056848#0150.001373#0150.000604#0150.002097#0150.000463#0150.000501#0150.000596#0150.000819#0150.000524#0150.000919#0150.002247#0150.069969#0150.001180#0150.000872#0150.000903#0150.000663#0150.059285#0150.000454#0150.000430#0150.069270#0150.000471#0150.000569#0150.000499#0150.003668#0150.000687#0150.014982#0150.000682#0150.152141#0150.001240#0150.000514#0150.001200#0150.004580#0150.001010#0150.000995#0150.000776#0150.211066#0150.000311#0150.000686#0150.000574#0150.000490#0150.000670#0150.063913#0150.001181#0150.001092#0150.000886#0150.000586#0150.000766#0150.000849#0150.001996#0150.000730#0150.000642#0150.000753#0150.008031#0150.000408#0150.000696#0150.000828#0150.157463#0150.001007#0150.000324#0150.000657#0150.385069#0150.001064#0150.000332#0150.000496#0150.013114#0150.000779#0150.002489#0150.003682#0150.000608#0150.163323#0150.003491#0150.002364#0150.001488#0150.004231#0150.002549#0150.108220#0150.008615#0150.001545#0150.092335#0150.001928#0150.115848#0150.002789#0150.003970#0150.003546#0150.001722#0150.000828#0150.004359#0150.088568#0150.003947#0150.003198#0150.002023#0150.042907#0150.002159#0150.018898#0150.002095#0150.003709#0150.003042#0150.002176#0150.003596#0150.002972#0150.002849#0150.007341#0150.003904#0150.002158#0150.004061#0150.001800#0150.001097#0150.002555#0150.002358#0150.000562#0150.002348#0150.000976#0150.002683#0150.001268#0150.000462#0150.002756#0150.000847#0150.001720#0150.000775#0150.001152#0150.000221#0150.000535#0150.000643#0150.000773#0150.008542#0150.001925#0150.001140#0150.067712#0150.000204#0150.000488#0150.002564#0150.002873#0150.002355#0150.000618#0150.000795#0150.000703#0150.000334#0150.000674#0150.000674#0150.000667#0150.001260#0150.021312#0150.006341#0150.000489#0150.000537#0150.000504#0150.000449#0150.000506#0150.000283#0150.000299#0150.000143#0150.000543#0150.000745#0150.000200#0150.000543#0150.000397#0150.000723#0150.000364#0150.000493#0150.000545#0150.000587#0150.000530#0150.000279#0150.000197#0150.000145#0150.000186#0150.000296#0150.000459#0150.000330#0150.000723#0150.000292#0150.000456#0150.000800#0150.167192#0150.000405#0150.000800#0150.001331#0150.000336#0150.002264#0150.000750#0150.000565#0150.000588#0150.000403#0150.000489#0150.000123#0150.000317#0150.000206#0150.000218#0150.002921#0150.000428#0150.002027#0150.000655#0150.000256#0150.001061#0150.000281#0150.000483#0150.000377#0150.000534#0150.000458#0150.000178#0150.000362#0150.000260#0150.000370#0150.001871#0150.000218#0150.000544#0150.000253#0150.000256#0150.008552#0150.000249#0150.000105#0150.000244#0150.127678#0150.000260#0150.000287#0150.000159#0150.000561#0150.000349#0150.000240#0150.000271#0150.000149#0150.121152#0150.000309#0150.000305#0150.110311#0150.106588#0150.048449#0150.000372#0150.000247#0150.000456#0150.000457#0150.000380#0150.000389#0150.000674#0150.000508#0150.000202#0150.000850#0150.000801#0150.000596#0150.000754#0150.000730#0150.000809#0150.000391#0150.000386#0150.017966#0150.000787#0150.000175#0150.000167#0150.000737#0150.001122#0150.000496#0150.001082#0150.000509#0150.000571#0150.000679#0150.000511#0150.000396#0150.000186#0150.000234#0150.166616#0150.000532#0150.000282#0150.000724#0150.000322#0150.000689#0150.024093#0150.001401#0150.000410#0150.024534#0150.000266#0150.000217#0150.000374#0150.000158#0150.000808#0150.000317#0150.000902#0150.001284#0150.147141#0150.004415#0150.000787#0150.047115#0150.002140#0150.000102#0150.000383#0150.018013#0150.000326#0150.038211#0150.069085#0150.048905#0150.005122#0150.002332#0150.002281#0150.001620#0150.002710#0150.001957#0150.000473#0150.001095#0150.000209#0150.000297#0150.000903#0150.269570#0150.002347#0150.003304#0150.118543#0150.000666#0150.000477#0150.000754#0150.005938#0150.000747#0150.000750#0150.000380#0150.000611#0150.000602#0150.000380#0150.000435#0150.000284#0150.000375#0150.000869#0150.000701#0150.140847#0150.000292#0150.000630#0150.000931#0150.000250#0150.000493#0150.000720#0150.000706#0150.000392#0150.000350#0150.000893#0150.007037#0150.000443#0150.001035#0150.000623#0150.000228#0150.000682#0150.000410#0150.000624#0150.000608#0150.043643#0150.000516#0150.000522#0150.000381#0150.000156#0150.000620#0150.009294#0150.003999#0150.000253#0150.000453#0150.000349#0150.000350#0150.000870#0150.001101#0150.000412#0150.066876#0150.000155#0150.000397#0150.000947#0150.000736#0150.000796#0150.000234#0150.000299#0150.127517#0150.000455#0150.000322#0150.000745#0150.000152#0150.000349#0150.000284#0150.000428#0150.000358#0150.001940#0150.000148#0150.000350#0150.000961#0150.000925#0150.000421#0150.000379#0150.001520#0150.000613#0150.003937#0150.000152#0150.141818#0150.000439#0150.000421#0150.000345#0150.000124#0150.294624#0150.000441#0150.000731#0150.000897#0150.029643#0150.000579#0150.001014#0150.000519#0150.000531#0150.000792#0150.001576#0150.000691#0150.001194#0150.000791#0150.000747#0150.000742#0150.000881#0150.000306#0150.000284#0150.000341#0150.001788#0150.000740#0150.000794#0150.000554#0150.000398#0150.000404#0150.001317#0150.000852#0150.000646#0150.000306#0150.000421#0150.000248#0150.001060#0150.000349#0150.000461#0150.000380#0150.000260#0150.000889#0150.000679#0150.000577#0150.000506#0150.000462#0150.000626#0150.000957#0150.232193#0150.000520#0150.000280#0150.000950#0150.000582#0150.000398#0150.000927#0150.000387#0150.000550#0150.000924#0150.000721#0150.000616#0150.048172#0150.000502#0150.000769#0150.000859#0150.002537#0150.000567#0150.000751#0150.000464#0150.000576#0150.000675#0150.000412#0150.000415#0150.000684#0150.000743#0150.000380#0150.000452#0150.000416#0150.001475#0150.079711#0150.000337#0150.000198#0150.000207#0150.001052#0150.000606#0150.000727#0150.000273#0150.000473#0150.177355#0150.000292#0150.001366#0150.005737#0150.000289#0150.001488#0150.004221#0150.000811#0150.000726#0150.000282#0150.064206#0150.001056#0150.000207#0150.004187#0150.009088#0150.002587#0150.005061#0150.000411#0150.001890#0150.000362#0150.000574#0150.000406#0150.020055#0150.018006#0150.000272#0150.000659#0150.000937#0150.074959#0150.000870#0150.000244#0150.001480#0150.000203#0150.002520#0150.000400#0150.000947#0150.000208#0150.000171#0150.000338#0150.000366#0150.000274#0150.083597#0150.000601#0150.000499#0150.000889#0150.000233#0150.000489#0150.000572#0150.000176#0150.000278#0150.000690#0150.000261#0150.000679#0150.000551#0150.002150#0150.000546#0150.148054#0150.000170#0150.000859#0150.000593#0150.000293#0150.000586#0150.000412#0150.000493#0150.000207#0150.000507#0150.261573#0150.000852#0150.000586#0150.000599#0150.019402#0150.039175#0150.002339#0150.000613#0150.000831#0150.000501#0150.001287#0150.000653#0150.000538#0150.000656#0150.001097#0150.000763#0150.010772#0150.000880#0150.000498#0150.001397#0150.000504#0150.000596#0150.000461#0150.000483#0150.004840#0150.000792#0150.000410#0150.000454#0150.000416#0150.000530#0150.000521#0150.024917#0150.000697#0150.000636#0150.000292#0150.000550#0150.000406#0150.002686#0150.000271#0150.000495#0150.000289#0150.000403#0150.000328#0150.000618#0150.000443#0150.000607#0150.000243#0150.000509#0150.001067#0150.000266#0150.000402#0150.000592#0150.000261#0150.000486#0150.000305#0150.000233#0150.000254#0150.000255#0150.000354#0150.000796#0150.000336#0150.000237#0150.000272#0150.000657#0150.000305#0150.000265#0150.000334#0150.000397#0150.000232#0150.000271#0150.000214#0150.000255#0150.000384#0150.000348#0150.000247#0150.000585#0150.000183#0150.000457#0150.000206#0150.000238#0150.000284#0150.068867#0150.000148#0150.000955#0150.000353#0150.000237#0150.000297#0150.000190#0150.000189#0150.000275#0150.001054#0150.000186#0150.000343#0150.000500#0150.000144#0150.000152#0150.000194#0150.000256#0150.000223#0150.001043#0150.000207#0150.000146#0150.000292#0150.000157#0150.000213#0150.000221#0150.000252#0150.000213#0150.000285#0150.000454#0150.000277#0150.018124#0150.000210#0150.000398#0150.000189#0150.000315#0150.000349#0150.000543#0150.000460#0150.000185#0150.000209#0150.000206#0150.000317#0150.000166#0150.000140#0150.000136#0150.000298#0150.000169#0150.000181#0150.000178#0150.000187#0150.118707#0150.033248#0150.000285#0150.000377#0150.000478#0150.000181#0150.000268#0150.000177#0150.000283#0150.000511#0150.000322#0150.000330#0150.000343#0150.000300#0150.000226#0150.000242#0150.000503#0150.000390#0150.000349#0150.000236#0150.000243#0150.000390#0150.000356#0150.000454#0150.000247#0150.000251#0150.000665#0150.000412#0150.000288#0150.000658#0150.000191#0150.000361#0150.000378#0150.025572#0150.000234#0150.000198#0150.000228#0150.000202#0150.000211#0150.000191#0150.000389#0150.000320#0150.000242#0150.000430#0150.000187#0150.000294#0150.000247#0150.000132#0150.000214#0150.000121#0150.000157#0150.000139#0150.000287#0150.000147#0150.000188#0150.000134#0150.000131#0150.012678#0150.000510#0150.000190#0150.015358#0150.000143#0150.000159#0150.000174#0150.000189#0150.000126#0150.000154#0150.000185#0150.000229#0150.000102#0150.000114#0150.000110#0150.000277#0150.000183#0150.000203#0150.000129#0150.000110#0150.000100#0150.000151#0150.000096#0150.000246#0150.000246#0150.000109#0150.000203#0150.000303#0150.000203#0150.000216#0150.000184#0150.000111#0150.000220#0150.000122#0150.000173#0150.000173#0150.000158#0150.000180#0150.000113#0150.000201#0150.000103#0150.000553#0150.000100#0150.001396#0150.000281#0150.000323#0150.000189#0150.000121#0150.000138#0150.000214#0150.003625#0150.000128#0150.000108#0150.000345#0150.000495#0150.000090#0150.036363#0150.000167#0150.000177#0150.000196#0150.000157#0150.000107#0150.000138#0150.000194#0150.000136#0150.143729#0150.000269#0150.000111#0150.000168#0150.000207#0150.000140#0150.000176#0150.000174#0150.000115#0150.000225#0150.000869#0150.000163#0150.000201#0150.000169#0150.000127#0150.000208#0150.000280#0150.000268#0150.004520#0150.000170#0150.000216#0150.000285#0150.000191#0150.000285#0150.000152#0150.000115#0150.000150#0150.000168#0150.000865#0150.000584#0150.000143#0150.000131#0150.000216#0150.054953#0150.000179#0150.000397#0150.000131#0150.001936#0150.000275#0150.000103#0150.000171#0150.000196#0150.000229#0150.000183#0150.000183#0150.000145#0150.002575#0150.000209#0150.000178#0150.033514#0150.000196#0150.000295#0150.000151#0150.000207#0150.000140#0150.000082#0150.000120#0150.000162#0150.000237#0150.000969#0150.000355#0150.000091#0150.000166#0150.000137#0150.000091#0150.000093#0150.000128#0150.000092#0150.000095#0150.000150#0150.000296#0150.000171#0150.000092#0150.000082#0150.000150#0150.000120#0150.062628#0150.000174#0150.000100#0150.000106#0150.000084#0150.000156#0150.000232#0150.000114#0150.000101#0150.000100#0150.010995#0150.000124#0150.000089#0150.000090#0150.000268#0150.000091#0150.000173#0150.000162#0150.000152#0150.000121#0150.000962#0150.000091#0150.000105#0150.000093#0150.000104#0150.000130#0150.000097#0150.000092#0150.000129#0150.000113#0150.000112#0150.000139#0150.000141#0150.000093#0150.000103#0150.000100#0150.000087#0150.000391#0150.000161#0150.000112#0150.000125#0150.000080#0150.000087#0150.000112#0150.000091#0150.000185#0150.000112#0150.000142#0150.000121#0150.000099#0150.000110#0150.000090#0150.000076#0150.000162#0150.023211#0150.000117#0150.000123#0150.000164#0150.000095#0150.000102#0150.197892#0150.000090#0150.000168#0150.000091#0150.000088#0150.243658#0150.000237#0150.000333#0150.000169#0150.000144#0150.000236#0150.000142#0150.000464#0150.000146#0150.000621#0150.000531#0150.000165#0150.000140#0150.000175#0150.000139#0150.000465#0150.000612#0150.000203#0150.000443#0150.000145#0150.000205#0150.000168#0150.000575#0150.000290#0150.000369#0150.000421#0150.000516#0150.000153#0150.000217#0150.000147#0150.000187#0150.000162#0150.000160#0150.000132#0150.000393#0150.000466#0150.000352#0150.000258#0150.000260#0150.000221#0150.195196#0150.000183#0150.000147#0150.000234#0150.000252#0150.000163#0150.000399#0150.000411#0150.000173#0150.000234#0150.000254#0150.001297#0150.000197#0150.000397#0150.000646#0150.000252#0150.000481#0150.001538#0150.000174#0150.000257#0150.000574#0150.000284#0150.000479#0150.000226#0150.000226#0150.000505#0150.001009#0150.032353#0150.000589#0150.000138#0150.000198#0150.000394#0150.000159#0150.000356#0150.000468#0150.000244#0150.000237#0150.000700#0150.000268#0150.000486#0150.000181#0150.000193#0150.000203#0150.000214#0150.000177#0150.000631#0150.000154#0150.000315#0150.000187#0150.000190#0150.000136#0150.000180#0150.000167#0150.000176#0150.000140#0150.000160#0150.000219#0150.000628#0150.000598#0150.000245#0150.000147#0150.000154#0150.000187#0150.000144#0150.000149#0150.000113#0150.000165#0150.000230#0150.000308#0150.000466#0150.000194#0150.000370#0150.000161#0150.000194#0150.022251#0150.000389#0150.000255#0150.000204#0150.000138#0150.000257#0150.000143#0150.000615#0150.000129#0150.000329#0150.000293#0150.000277#0150.000182#0150.026130#0150.000319#0150.000107#0150.000323#0150.000295#0150.000117#0150.000929#0150.000120#0150.000134#0150.000127#0150.000130#0150.000216#0150.000116#0150.000193#0150.000140#0150.000312#0150.001063#0150.000122#0150.000148#0150.000119#0150.000326#0150.000281#0150.000694#0150.000266#0150.000403#0150.000251#0150.000172#0150.001479#0150.000153#0150.000117#0150.000159#0150.000182#0150.000172#0150.000119#0150.000997#0150.000320#0150.000180#0150.000156#0150.000123#0150.018878#0150.000519#0150.000086#0150.000590#0150.000091#0150.000132#0150.000195#0150.000206#0150.000130#0150.000228#0150.000134#0150.000137#0150.010255#0150.000156#0150.000108#0150.000097#0150.000156#0150.000285#0150.000129#0150.000404#0150.000140#0150.000138#0150.000199#0150.000134#0150.000156#0150.000102#0150.000153#0150.000100#0150.000141#0150.000787#0150.000140#0150.000238#0150.000139#0150.000123#0150.000151#0150.000324#0150.000304#0150.000156#0150.000114#0150.000169#0150.022881#0150.000172#0150.000158#0150.000164#0150.000106#0150.000449#0150.000220#0150.000292#0150.000303#0150.000367#0150.000314#0150.000181#0150.000110#0150.000223#0150.000188#0150.000129#0150.000327#0150.000139#0150.000453#0150.000111#0150.049403#0150.000115#0150.000361#0150.000398#0150.000224#0150.000106#0150.000148#0150.000179#0150.000446#0150.000190#0150.000103#0150.000126#0150.000115#0150.000115#0150.000085#0150.000128#0150.000077#0150.000274#0150.000147#0150.000131#0150.000094#0150.000377#0150.000166#0150.000094#0150.000337#0150.000089#0150.000150#0150.000127#0150.000113#0150.000150#0150.000110#0150.000275#0150.000092#0150.000179#0150.000132#0150.000325#0150.000207#0150.000111#0150.000300#0150.000287#0150.000097#0150.000099#0150.000160#0150.000156#0150.000133#0150.000134#0150.000252#0150.000473#0150.000141#0150.000106#0150.000122#0150.000116#0150.000253#0150.000154#0150.000397#0150.000231#0150.000128#0150.000428#0150.000115#0150.000125#0150.000174#0150.000289#0150.000229#0150.000141#0150.000261#0150.000120#0150.000208#0150.000295#0150.000108#0150.000146#0150.000165#0150.147390#0150.000169#0150.000382#0150.000263Evaluate the following checkpoints:  ['./outputs/checkpoint-1200', './outputs/checkpoint-1600', './outputs/checkpoint-400', './outputs/checkpoint-800']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-09-17 01:45:37,196 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-09-17 01:46:36 Uploading - Uploading generated training model\n",
      "2019-09-17 01:47:37 Completed - Training job completed\n",
      "Training seconds: 1014\n",
      "Billable seconds: 1014\n"
     ]
    }
   ],
   "source": [
    "estimator.fit('s3://sagemaker-us-east-1-665028136136/compliance-data/batch2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://sagemaker-us-east-1-665028136136/${estimator.latest_training_job.name}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model into SageMaker\n",
    "The PyTorch model uses a npy serializer and deserializer by default. since we have a custom implementation of all the hosting functions and plan on using JSON instead, we need a predictor that can serialize and deserialize JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor, json_serializer, json_deserializer\n",
    "\n",
    "class JSONPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(JSONPredictor, self).__init__(endpoint_name, sagemaker_session, json_serializer, json_deserializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since hosting functions implemented outside of train script we can't just use estimator object to deploy the model. Instead we need to create a PyTorchModel object using the latest training job to get the S3 location of the trained model data. Besides model data location in S3, we also need to configure PyTorchModel with the script and source directory (because our generate script requires model and data classes from source directory), an IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "trained_model_location = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "model = PyTorchModel(model_data=trained_model_location,\n",
    "                     role=role,\n",
    "                     framework_version='1.1.0',\n",
    "                     entry_point='inference.py',\n",
    "                     source_dir='email-compliance-bert',\n",
    "                     #git_config=git_config,\n",
    "                     predictor_cls=JSONPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create endpoint\n",
    "Now the model is ready to be deployed at a SageMaker endpoint and we are going to use the sagemaker.pytorch.model.PyTorchModel.deploy method to do this. We can use a CPU-based instance for inference (in this case an ml.m4.xlarge), even though we trained on GPU instances, because at the end of training we moved model to cpu before returning it. This way we can load trained model on any device and then move to GPU if CUDA is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Endpoint Configuration\n",
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'EmailComplianceEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sagemaker.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.xlarge',\n",
    "        'InitialInstanceCount':2,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic',\n",
    "        'AcceleratorType':'ml.eia1.medium'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'EmailComplianceEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_response = sagemaker.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=2, instance_type='ml.m5.xlarge')\n",
    "#https://aws.amazon.com/machine-learning/elastic-inference/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-pytorch-2019-09-17-01-54-42-510'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_song=\"\"\"\n",
    "Hello, it's me.\n",
    "I was wondering if after all these years you'd like to meet.\n",
    "To go over everything.\n",
    "They say that time's supposed to heal you.\n",
    "But I ain't done much healing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response= 1 0.9275727272033691\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "start_t=time.time()\n",
    "input_json = {\n",
    "    'txt': hello_song\n",
    "}\n",
    "d=json.dumps(input_json)\n",
    "response = predictor.predict(input_json)\n",
    "print(\"response=\", response, time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response= {'ResponseMetadata': {'RequestId': '65b1e034-25aa-445c-9100-41c35b8a2b62', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '65b1e034-25aa-445c-9100-41c35b8a2b62', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Tue, 17 Sep 2019 02:21:13 GMT', 'content-type': 'application/json', 'content-length': '3'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7f0f86096710>} 0.9273343086242676\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker',region_name='us-east-1')\n",
    "#endpoint_name = 'sagemaker-pytorch-2019-09-15-13-33-39-536'\n",
    "endpoint_name = predictor.endpoint\n",
    "start_t=time.time()\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    " ContentType='application/json',\n",
    " Body=d)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(\"response=\", response, time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup\n",
    "To delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\r\n",
      "uuid\r\n",
      "pytorch-transformers\r\n"
     ]
    }
   ],
   "source": [
    "!more requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2017-2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\"). You\r\n",
      "# may not use this file except in compliance with the License. A copy of\r\n",
      "# the License is located at\r\n",
      "#\r\n",
      "#     http://aws.amazon.com/apache2.0/\r\n",
      "#\r\n",
      "# or in the \"license\" file accompanying this file. This file is\r\n",
      "# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\r\n",
      "# ANY KIND, either express or implied. See the License for the specific\r\n",
      "# language governing permissions and limitations under the License.\r\n",
      "\r\n",
      "# For more information on creating a Dockerfile\r\n",
      "# https://docs.docker.com/compose/gettingstarted/#step-2-create-a-dockerfile\r\n",
      "# https://github.com/awslabs/amazon-sagemaker-examples/master/advanced_functionality/pytorch_extending_our_containers/pytorch_extending_our_containers.ipynb\r\n",
      "# SageMaker PyTorch image\r\n",
      "FROM 520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-pytorch:1.1.0-cpu-py3\r\n",
      "\r\n",
      "ENV PATH=\"/opt/ml/code:${PATH}\"\r\n",
      "\r\n",
      "# /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code.\r\n",
      "COPY /email-compliance-bert /opt/ml/code\r\n",
      "RUN pip install -r /opt/ml/code/requirements.txt\r\n",
      "# this environment variable is used by the SageMaker PyTorch container to determine our user code directory.\r\n",
      "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\r\n",
      "\r\n",
      "# this environment variable is used by the SageMaker PyTorch container to determine our program entry point\r\n",
      "# for training and serving.\r\n",
      "# For more information: https://github.com/aws/sagemaker-pytorch-container\r\n",
      "ENV SAGEMAKER_PROGRAM inference.py\r\n"
     ]
    }
   ],
   "source": [
    "!cat Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !./build_and_push.sh sagemaker-pytorch-email-compliance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
